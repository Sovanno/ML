{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64a7dd8d-04f0-44d0-bdf8-011927ccf756",
   "metadata": {},
   "source": [
    "# Задание 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559b1e30-925f-4784-aedc-7585f1c62b45",
   "metadata": {},
   "source": [
    "## Решить задачи регрессии и классификации на данных в соответствии с Вашим индивидуальным вариантом (см. Лаб.работы №3, 4), используя полносвязные НС; реализовать НС посредством API Keras и фреймворка TensorFlow; оценить качество полученных моделей с помощью метрик."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b7b3aa7-696d-49f9-9bbc-6039a60bef85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4946ce18-2f0e-44c9-8df8-7a8f731e8b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class = pd.read_csv('..\\data\\weatherAUS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91839b22-ee11-48ac-8110-46af430c9987",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df_class.columns:\n",
    "    if df_class[column].dtype == 'int64':\n",
    "        df_class[column].fillna(df_class[column].median(), inplace=True)\n",
    "    elif df_class[column].dtype == 'float64':\n",
    "        df_class[column].fillna(df_class[column].mean(), inplace=True)\n",
    "    else:\n",
    "        df_class[column].fillna(df_class[column].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39af2238-87a2-4326-a12f-8af5a0324dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class = df_class.rename (\n",
    "    columns = {\n",
    "        'Date' : 'date',\n",
    "        'Location' : 'location',\n",
    "        'MinTemp' : 'min_temp',\n",
    "        'MaxTemp' : 'max_temp',\n",
    "        'Rainfall' : 'rainfall',\n",
    "        'Evaporation' : 'evaporation',\n",
    "        'Sunshine' : 'sunshine',\n",
    "        'WindGustDir' : 'wind_gust_dir',\n",
    "        'WindGustSpeed' : 'wind_gust_speed',\n",
    "        'WindDir9am' : 'wind_dir_9am',\n",
    "        'WindDir3pm' : 'wind_dir_3pm',\n",
    "        'WindSpeed9am' : 'wind_speed_9am',\n",
    "        'WindSpeed3pm' : 'wind_speed_3pm',\n",
    "        'Humidity9am' : 'humidity_9am',\n",
    "        'Humidity3pm' : 'humidity_3pm',\n",
    "        'Pressure9am' : 'pressure_9am',\n",
    "        'Pressure3pm' : 'pressure_3pm',\n",
    "        'Cloud9am' : 'cloud_9am',\n",
    "        'Cloud3pm' : 'cloud_3pm',\n",
    "        'Temp9am' : 'temp_9am',\n",
    "        'Temp3pm' : 'temp_3pm',\n",
    "        'RainToday' : 'rain_today',\n",
    "        'RainTomorrow' : 'rain_tomorrow'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33c6b62c-b85c-40c7-ab8b-406dbda6824a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class = df_class.drop(['date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8e64fd4-d7c9-4444-8619-ecf66b70b393",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class = df_class.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b18d9a69-7d28-4c10-ae5b-44267e182b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class['location'] = pd.Categorical(df_class['location']).codes\n",
    "df_class['wind_gust_dir'] = pd.Categorical(df_class['wind_gust_dir']).codes\n",
    "df_class['wind_dir_9am'] = pd.Categorical(df_class['wind_dir_9am']).codes\n",
    "df_class['wind_dir_3pm'] = pd.Categorical(df_class['wind_dir_3pm']).codes\n",
    "df_class['rain_today'] = pd.Categorical(df_class['rain_today']).codes\n",
    "df_class['rain_tomorrow'] = pd.Categorical(df_class['rain_tomorrow']).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3b5b874-f229-4a13-86be-b2552049f6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_class.drop(['rain_tomorrow'], axis=1)\n",
    "y = df_class['rain_tomorrow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b2ae8d6-6011-4f68-852b-723070daaf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17cdaf48-099b-450b-a99f-947bcab9ee7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = StandardScaler()\n",
    "X_normalized_zscore = normalizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8851472a-ede9-48cc-9bb6-3dea2aa0b5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Создание экземпляра RandomUnderSampler\n",
    "rus = RandomUnderSampler()\n",
    "\n",
    "# Применение уменьшения выборки к данным\n",
    "X, y = rus.fit_resample(X_normalized_zscore, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3c70466-b1b8-4979-94dd-1508e29346a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61684a37-3539-4660-8381-1975558217b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = pd.read_csv('..\\data\\diamonds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1360f97-7274-44ab-8e29-a612cb9f1a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_reg['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09383203-c19c-4e07-8b38-4d8602f8c242",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = df_reg.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7daeba3f-2f1b-44aa-85ee-93420ebaac61",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_cut = {'Ideal': 5,\n",
    "            'Premium': 4,\n",
    "            'Very Good': 3,\n",
    "            'Good': 2,\n",
    "            'Fair': 1}\n",
    "\n",
    "df_reg['cut'] = df_reg['cut'].map(dict_cut)\n",
    "\n",
    "dict_color = {'D': 7,\n",
    "              'E': 6,\n",
    "              'F': 5,\n",
    "              'G': 4,\n",
    "              'H': 3,\n",
    "              'I': 2,\n",
    "              'J': 1}\n",
    "\n",
    "df_reg['color'] = df_reg['color'].map(dict_color)\n",
    "\n",
    "dict_clarity = {'IF': 8,\n",
    "              'VVS1': 7,\n",
    "              'VVS2': 6,\n",
    "              'VS1': 5,\n",
    "              'VS2': 4,\n",
    "              'SI1': 3,\n",
    "              'SI2': 2,\n",
    "              'I1': 1}\n",
    "\n",
    "df_reg['clarity'] = df_reg['clarity'].map(dict_clarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6741e8c8-0108-452f-985b-44b69946717d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_reg = df_reg[\"price\"]\n",
    "X_reg = df_reg.drop([\"price\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1be1c7fb-fc32-4e3e-bbb6-e0a1a35b1e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37baa17f-f44e-4b22-8bad-813edf58188a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (2.13.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.24.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.15.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.58.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.23.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.3.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e65e14a-673e-454b-b506-0c1ee51fc3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (2.13.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55987d61-3e04-4e23-9c60-db0cb1a19d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\sovano\\desktop\\ml\\venv\\lib\\site-packages (22.3.1)\n",
      "Collecting pip\n",
      "  Downloading pip-23.3.2-py3-none-any.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 939.6 kB/s eta 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: To modify pip, please run the following command:\n",
      "C:\\Users\\Sovano\\Desktop\\ML\\venv\\Scripts\\python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e3ed7da-8fc8-4333-98e8-7066fe82b200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e7c94d-7e0a-46e4-81ea-04a6d9e52a1d",
   "metadata": {},
   "source": [
    "- Создадим модель с помощью tf.keras.Sequential().\n",
    "- Добавим слои к модели с помощью метода .add(). Для задач регрессии можно использовать слои Dense, а для задач классификации - Dense в сочетании с активационной функцией sigmoid (для бинарной классификации)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b897f47c-341c-4542-8827-785cfe741859",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg = tf.keras.Sequential()\n",
    "model_class = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "921e6055-1e26-442e-863f-cf5a33ec56bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg.add(tf.keras.layers.Dense(64, activation='relu', input_shape=(9,)))\n",
    "model_reg.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
    "# Dropout позволяет внести фактор случайности - при обучении часть нейронов будет отключаться\n",
    "# каждый нейрон, в данном случае, будет отключаться с вероятностью 0.1\n",
    "model_reg.add(tf.keras.layers.Dropout(0.1))\n",
    "model_reg.add(tf.keras.layers.Dense(16, activation=\"relu\"))\n",
    "model_reg.add(tf.keras.layers.Dropout(0.1))\n",
    "model_reg.add(tf.keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d082d2e-8743-4aa5-a701-f3d24ba9def2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                640       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3265 (12.75 KB)\n",
      "Trainable params: 3265 (12.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# посмотрим, какая сеть у нас получилась\n",
    "model_reg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd4b4582-fb5e-4404-86a8-8a61ee820d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class.add(tf.keras.layers.Dense(64, activation='relu', input_shape=(21,)))\n",
    "model_class.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n",
    "model_class.add(tf.keras.layers.Dropout(0.05))\n",
    "model_class.add(tf.keras.layers.Dense(64, activation=\"relu\"))\n",
    "model_class.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
    "model_class.add(tf.keras.layers.Dense(16, activation=\"relu\"))\n",
    "model_class.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48ad815a-77ee-4d53-aea6-ce903c324441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 64)                1408      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20609 (80.50 KB)\n",
      "Trainable params: 20609 (80.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_class.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae6ee22-a0ba-446c-bb15-2ae5a2a418da",
   "metadata": {},
   "source": [
    "Скомпилируем модели с помощью .compile(). Укажем функцию потерь (loss), оптимизатор (optimizer) и метрики (metrics), которые будем использовать для оценки модели. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a48a9f1a-fbf0-4916-8af4-cc8747b54b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# компилируем\n",
    "model_reg.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9b1e58e-46fd-4f0f-bb55-cedb555d003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=\"binary_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237bf617-1190-49d9-a7a2-1e853511eeff",
   "metadata": {},
   "source": [
    " Обучаем модель с помощью .fit(). Установливаем количество эпох (epochs), а также передаём обучающие данные и целевые значения. Можем передать размер пакета (batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0366a96-30c1-413b-a4bc-6943b167d7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1345/1345 [==============================] - 3s 2ms/step - loss: 5321882.0000\n",
      "Epoch 2/50\n",
      "1345/1345 [==============================] - 2s 1ms/step - loss: 1860029.8750\n",
      "Epoch 3/50\n",
      "1345/1345 [==============================] - 2s 1ms/step - loss: 1824675.6250\n",
      "Epoch 4/50\n",
      "1345/1345 [==============================] - 2s 2ms/step - loss: 1620334.2500\n",
      "Epoch 5/50\n",
      "1345/1345 [==============================] - 2s 2ms/step - loss: 1520893.5000\n",
      "Epoch 6/50\n",
      "1345/1345 [==============================] - 2s 2ms/step - loss: 1466722.7500\n",
      "Epoch 7/50\n",
      "1345/1345 [==============================] - 2s 2ms/step - loss: 1388045.6250\n",
      "Epoch 8/50\n",
      "1345/1345 [==============================] - 2s 2ms/step - loss: 1323220.5000\n",
      "Epoch 9/50\n",
      "1345/1345 [==============================] - 2s 2ms/step - loss: 1314001.1250\n",
      "Epoch 10/50\n",
      "1345/1345 [==============================] - 2s 1ms/step - loss: 1309104.5000\n",
      "Epoch 11/50\n",
      "1345/1345 [==============================] - 2s 2ms/step - loss: 1244185.2500\n",
      "Epoch 12/50\n",
      "1345/1345 [==============================] - 2s 1ms/step - loss: 1240787.2500\n",
      "Epoch 13/50\n",
      "1345/1345 [==============================] - 2s 2ms/step - loss: 1211676.3750\n",
      "Epoch 14/50\n",
      "1345/1345 [==============================] - 2s 2ms/step - loss: 1197278.2500\n",
      "Epoch 15/50\n",
      "1345/1345 [==============================] - 2s 2ms/step - loss: 1221698.7500\n",
      "Epoch 16/50\n",
      "1345/1345 [==============================] - 2s 2ms/step - loss: 1185968.7500\n",
      "Epoch 17/50\n",
      "1345/1345 [==============================] - 1s 1ms/step - loss: 1156145.2500\n",
      "Epoch 18/50\n",
      "1345/1345 [==============================] - 2s 1ms/step - loss: 1158562.7500\n",
      "Epoch 19/50\n",
      "1345/1345 [==============================] - 2s 1ms/step - loss: 1141728.8750\n",
      "Epoch 20/50\n",
      "1345/1345 [==============================] - 2s 1ms/step - loss: 1157753.8750\n",
      "Epoch 21/50\n",
      "1345/1345 [==============================] - 2s 2ms/step - loss: 1124390.6250\n",
      "Epoch 22/50\n",
      "1345/1345 [==============================] - 2s 1ms/step - loss: 1117602.0000\n",
      "Epoch 23/50\n",
      "1345/1345 [==============================] - 2s 2ms/step - loss: 1112596.6250\n",
      "Epoch 24/50\n",
      "1345/1345 [==============================] - 2s 2ms/step - loss: 1128017.8750\n",
      "Epoch 25/50\n",
      "1345/1345 [==============================] - 2s 2ms/step - loss: 1126310.6250\n",
      "Epoch 26/50\n",
      "1345/1345 [==============================] - 2s 1ms/step - loss: 1072201.6250\n",
      "Epoch 27/50\n",
      "1345/1345 [==============================] - 2s 2ms/step - loss: 1092812.2500\n",
      "Epoch 28/50\n",
      "1345/1345 [==============================] - 2s 1ms/step - loss: 1113759.7500\n",
      "Epoch 29/50\n",
      "1345/1345 [==============================] - 2s 1ms/step - loss: 1116767.0000\n",
      "Epoch 30/50\n",
      "1345/1345 [==============================] - 2s 2ms/step - loss: 1080183.2500\n",
      "Epoch 31/50\n",
      "1345/1345 [==============================] - 2s 2ms/step - loss: 1094279.2500\n",
      "Epoch 32/50\n",
      "1345/1345 [==============================] - 2s 1ms/step - loss: 1061349.7500\n",
      "Epoch 33/50\n",
      "1345/1345 [==============================] - 2s 1ms/step - loss: 1081398.8750\n",
      "Epoch 34/50\n",
      "1345/1345 [==============================] - 2s 2ms/step - loss: 1069846.7500\n",
      "Epoch 35/50\n",
      "1345/1345 [==============================] - 2s 1ms/step - loss: 1035264.4375\n",
      "Epoch 36/50\n",
      "1345/1345 [==============================] - 2s 1ms/step - loss: 1049845.6250\n",
      "Epoch 37/50\n",
      "1345/1345 [==============================] - 2s 2ms/step - loss: 1061543.6250\n",
      "Epoch 38/50\n",
      "1345/1345 [==============================] - 2s 1ms/step - loss: 1041492.0000\n",
      "Epoch 39/50\n",
      "1345/1345 [==============================] - 2s 2ms/step - loss: 1042756.6250\n",
      "Epoch 40/50\n",
      "1345/1345 [==============================] - 2s 2ms/step - loss: 1050572.0000\n",
      "Epoch 41/50\n",
      "1345/1345 [==============================] - 2s 2ms/step - loss: 1026641.1250\n",
      "Epoch 42/50\n",
      "1345/1345 [==============================] - 2s 1ms/step - loss: 1029144.3750\n",
      "Epoch 43/50\n",
      "1345/1345 [==============================] - 2s 1ms/step - loss: 993491.6250\n",
      "Epoch 44/50\n",
      "1345/1345 [==============================] - 2s 2ms/step - loss: 1008038.3125\n",
      "Epoch 45/50\n",
      "1345/1345 [==============================] - 2s 1ms/step - loss: 1002839.3125\n",
      "Epoch 46/50\n",
      "1345/1345 [==============================] - 2s 1ms/step - loss: 1005737.6250\n",
      "Epoch 47/50\n",
      "1345/1345 [==============================] - 2s 1ms/step - loss: 991677.4375\n",
      "Epoch 48/50\n",
      "1345/1345 [==============================] - 2s 1ms/step - loss: 995295.0000\n",
      "Epoch 49/50\n",
      "1345/1345 [==============================] - 2s 2ms/step - loss: 986307.5625\n",
      "Epoch 50/50\n",
      "1345/1345 [==============================] - 2s 1ms/step - loss: 988999.8750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x246fd8720d0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_reg.fit(X_train_reg, y_train_reg, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d9736f9-6665-4e4e-8c24-5098a15639a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x246fdc620d0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_class.fit(X_train_class, y_train_class, epochs=25, verbose=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422138a7-f75e-4689-8ef5-7abdae03b830",
   "metadata": {},
   "source": [
    " Оценим качество модели с помощью метрик, таких как accuracy для задач классификации или mean_squared_error для задач регрессии. Процесс оценки может быть выполнен с помощью метода .evaluate()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64a94bd4-9e59-45ec-9707-a92090d3c1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b347bfc6-9526-4163-8779-77cd1aa19b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337/337 [==============================] - 0s 1ms/step\n",
      "435.4504342822406\n",
      "337/337 [==============================] - 0s 1ms/step\n",
      "514421.49726574623\n"
     ]
    }
   ],
   "source": [
    "# оцениваем качество с помощью метрик\n",
    "print(mean_absolute_error(y_test_reg, model_reg.predict(X_test_reg)))\n",
    "print(mean_squared_error(y_test_reg, model_reg.predict(X_test_reg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2196f4e-5515-47c5-988b-5dbc6644c60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337/337 [==============================] - 1s 1ms/step - loss: 514421.3750\n",
      "Loss: 514421.375\n"
     ]
    }
   ],
   "source": [
    "loss = model_reg.evaluate(X_test_reg, y_test_reg)\n",
    "\n",
    "print('Loss:', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2760eae5-02c6-46aa-817d-afa125988ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4754 - accuracy: 0.7823\n",
      "Loss: 0.4753812551498413\n",
      "Accuracy: 0.7822744846343994\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model_class.evaluate(X_test_class, y_test_class)\n",
    "\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b181148-1fa0-410b-b096-c80b2033629a",
   "metadata": {},
   "source": [
    "# Задание 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e7acff-d5eb-4ec6-870e-cefe5a1367e0",
   "metadata": {},
   "source": [
    "## Разработать многослойный персептрон (MLP), с помощью которого можно решать задачи регрессии и классификации. Предусмотреть возможность использования таких функции активации, как sigmoid, tanh и relu; также предусмотреть возможность указать, сколько слоев нужно, сколько на каждом из них нейронов и какую функцию активации должен иметь слой. Реализовать обучение MLP методом обратного распространения ошибки; самостоятельно найти производные функций sigmoid, tanh и relu; реализовать классический градиентный спуск с возможностью указания шага."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c11e81c-78bf-4c39-b139-cecb2771d05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f0178738-5aa3-493a-8dbd-9dbcb848c556",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, num_layers, num_neurons, activation_functions):\n",
    "        self.num_layers = num_layers\n",
    "        self.num_neurons = num_neurons\n",
    "        self.activation_functions = activation_functions\n",
    "\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            if i == 0:\n",
    "                input_size = self.num_neurons[i]\n",
    "            else:\n",
    "                input_size = self.num_neurons[i-1]\n",
    "\n",
    "            weight = np.random.randn(input_size, self.num_neurons[i])\n",
    "            bias = np.zeros((1, self.num_neurons[i]))\n",
    "\n",
    "            self.weights.append(weight)\n",
    "            self.biases.append(bias)\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def tanh(self, x):\n",
    "        return np.tanh(x)\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.layer_outputs = []\n",
    "        self.activations = []\n",
    "\n",
    "        input_data = X\n",
    "        for i in range(self.num_layers):\n",
    "            layer_output = np.dot(input_data, self.weights[i]) + self.biases[i]\n",
    "\n",
    "            if self.activation_functions[i] == 'sigmoid':\n",
    "                activation = self.sigmoid(layer_output)\n",
    "            elif self.activation_functions[i] == 'relu':\n",
    "                activation = self.relu(layer_output)\n",
    "            elif self.activation_functions[i] == 'tanh':\n",
    "                activation = self.tanh(layer_output)\n",
    "            else:\n",
    "                raise ValueError('Unknown activation function')\n",
    "\n",
    "            self.layer_outputs.append(layer_output)\n",
    "            self.activations.append(activation)\n",
    "\n",
    "            input_data = activation\n",
    "\n",
    "        return activation\n",
    "\n",
    "    def backward(self, X, y, learning_rate):\n",
    "        batch_size = X.shape[0]\n",
    "\n",
    "        gradients = []\n",
    "        for i in reversed(range(self.num_layers)):\n",
    "            if i == self.num_layers - 1:\n",
    "                output_error = self.activations[i] - y\n",
    "            else:\n",
    "                output_error = np.dot(gradients[0], self.weights[i+1].T)\n",
    "\n",
    "            activation_derivative = self.derivative(self.activation_functions[i], self.layer_outputs[i])\n",
    "\n",
    "            gradient = output_error * activation_derivative\n",
    "            gradients.insert(0, gradient)\n",
    "            #print(gradient.shape, activation_derivative.shape, gradients[0].shape)\n",
    "\n",
    "            batch_size = X.shape[0] if i == 0 else self.activations[i-1].shape[0]\n",
    "            weight_gradient = np.dot(self.activations[i].T, gradient) / batch_size\n",
    "            bias_gradient = np.mean(gradient, axis=0, keepdims=True)\n",
    "\n",
    "            self.weights[i] -= learning_rate * weight_gradient\n",
    "            self.biases[i] -= learning_rate * bias_gradient\n",
    "\n",
    "    def derivative(self, activation_function, x):\n",
    "        if activation_function == 'sigmoid':\n",
    "            return self.sigmoid(x) * (1 - self.sigmoid(x))\n",
    "        elif activation_function == 'relu':\n",
    "            return np.where(x <= 0, 0, 1)\n",
    "        elif activation_function == 'tanh':\n",
    "            return 1 - np.tanh(x) ** 2\n",
    "        else:\n",
    "            raise ValueError('Unknown activation function')\n",
    "\n",
    "    def fit(self, X_train, y_train, epochs, learning_rate):\n",
    "        for epoch in range(epochs):\n",
    "            indices = np.random.permutation(X_train.shape[0])\n",
    "            X_train_shuffled = X_train[indices]\n",
    "            y_train_shuffled = y_train[indices]\n",
    "\n",
    "            for i in range(0, X_train.shape[0]):\n",
    "                X_batch = X_train_shuffled[i:i+1]\n",
    "                y_batch = y_train_shuffled[i:i+1]\n",
    "\n",
    "                self.forward(X_batch)\n",
    "                self.backward(X_batch, y_batch, learning_rate)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1bd16101-e70b-436b-a9a0-14b17f06d034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание MLP для задачи регрессии\n",
    "mlp_regression = MLP(num_layers=3, num_neurons=[9, 9, 1], activation_functions=['relu', 'tanh', 'relu'])\n",
    "mlp_regression.fit(np.array(X_train_reg), np.array(y_train_reg), epochs=20, learning_rate=0.005)\n",
    "predictions_regression = mlp_regression.predict(X_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b0d55d18-eec5-4dcb-9181-7fec62aace35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3958.600892276234\n",
      "31655243.851008456\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(np.array(y_test_reg), np.array(predictions_regression)))\n",
    "print(mean_squared_error(y_test_reg, predictions_regression))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7856b474-6a15-4bd1-a6b3-f88a514c69e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sovano\\AppData\\Local\\Temp\\ipykernel_15272\\3835661000.py:23: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "# Создание MLP для задачи классификации\n",
    "mlp_classification = MLP(num_layers=3, num_neurons=[21, 21, 1], activation_functions=['relu', 'sigmoid', 'sigmoid'])\n",
    "mlp_classification.fit(np.array(X_train_class), np.array(y_train_class), epochs=20, learning_rate=0.005)\n",
    "predictions_classification = mlp_classification.predict(X_test_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "760f240b-1747-493c-8da1-b61c9a5f7272",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "009be82d-35c8-4882-ab07-8d63279db43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6054117647058823"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_class, np.round(predictions_classification))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d849f3-b51b-430f-b163-a4ec0e4dea1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
